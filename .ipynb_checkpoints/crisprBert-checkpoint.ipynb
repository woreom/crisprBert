{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa63822",
   "metadata": {},
   "source": [
    "# Find dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0d4a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-04 11:25:16--  https://cdn-datasets.huggingface.co/EsperBERTo/data/oscar.eo.txt\n",
      "Resolving cdn-datasets.huggingface.co (cdn-datasets.huggingface.co)... 13.224.193.51, 13.224.193.95, 13.224.193.13, ...\n",
      "Connecting to cdn-datasets.huggingface.co (cdn-datasets.huggingface.co)|13.224.193.51|:443... connected.\n",
      "Unable to establish SSL connection.\n"
     ]
    }
   ],
   "source": [
    "# in this notebook we'll only get one of the files (the Oscar one) for the sake of simplicity and performance\n",
    "# !wget -c https://cdn-datasets.huggingface.co/EsperBERTo/data/oscar.eo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79ad9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"../dnabert/examples/unprocessed_data/unlabeled_sgrna_fixed.csv\")\n",
    "\n",
    "# with open(\"../dnabert/examples/unprocessed_data/unlabeled_sgrna_fixed.txt\",\"w\") as f:\n",
    "#     for i in df[\"sgRNA\"]:\n",
    "#         f.write(i+\"\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7157a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp ../dnabert/examples/unprocessed_data/unlabeled_sgrna_fixed.txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99125f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unlabeled_sgrna_fixed.txt']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
    "\n",
    "\n",
    "print(paths)\n",
    "\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d20a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/d/M3/Projects/BCB/crisprBert/Models/crisprBert/vocab.json',\n",
       " '/mnt/d/M3/Projects/BCB/crisprBert/Models/crisprBert/merges.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model(\"/mnt/d/M3/Projects/BCB/crisprBert/Models/crisprBert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b79c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"/mnt/d/M3/Projects/BCB/crisprBert/Models/crisprBert/vocab.json\",\n",
    "    \"/mnt/d/M3/Projects/BCB/crisprBert/Models/crisprBert/merges.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b84c94ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"CGCCGCCGCTTTCGGTGATGAGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74af00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CGCCGCC', 'GCTTT', 'CGGT', 'GATGAGG']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"CGCCGCCGCTTTCGGTGATGAGG\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac3d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crisprBert",
   "language": "python",
   "name": "crisprbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
